{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tractorjuice/Building_BoK/blob/main/Building_Wardley_Mapping_Body_of_Knowledge_Part_2b_Speech_to_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07c1e3b9"
      },
      "source": [
        "# Wardley Mapping Body of Knowledge Using Langchain & OpenAI\n",
        "## Part 2, transcribe the audio files\n",
        "\n",
        "This example shows how to create and query an internal knowledge base using ChatGPT.\n",
        "\n",
        "This requires a GPU runtime."
      ],
      "id": "07c1e3b9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZMGuOEMrG2V"
      },
      "source": [
        "## Runtime Checks"
      ],
      "id": "pZMGuOEMrG2V"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAdXR7juCN_5"
      },
      "source": [
        "Check we are running on a GPU and check the available memory"
      ],
      "id": "DAdXR7juCN_5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b95p5xdwLUSC"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  gpu_info = !nvidia-smi\n",
        "except:\n",
        "  print('No GPU')\n",
        "else:\n",
        "  gpu_info = '\\n'.join(gpu_info)\n",
        "  if gpu_info.find('failed') >= 0:\n",
        "    print('Not connected to a GPU')\n",
        "  print(gpu_info)"
      ],
      "id": "b95p5xdwLUSC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hi64puI8Lf--"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "id": "Hi64puI8Lf--"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UqlAAxTXnGF"
      },
      "source": [
        "## Set Up\n"
      ],
      "id": "0UqlAAxTXnGF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3l-ZazUZPR2"
      },
      "source": [
        "Mount Google Drive"
      ],
      "id": "K3l-ZazUZPR2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trki7a-jZNzf"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "trki7a-jZNzf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwk0Vu46YWjQ"
      },
      "source": [
        "Check audio files are stored on Google Drive"
      ],
      "id": "Kwk0Vu46YWjQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ze4wgstKYprq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "KB_FOLDER = \"/content/gdrive/MyDrive/WardleyKB\"  # Google drive folder to save the knowledgebase\n",
        "YT = os.path.join(KB_FOLDER, \"youtube\")  # Sub-directory for YouTube FAIS datastore files\n",
        "YT_DATASTORE = os.path.join(YT, \"datastore\")  # Sub-directory for YouTube FAIS datastore files\n",
        "YT_AUDIO = os.path.join(YT, \"audio\")  # Sub-directory for audio files\n",
        "YT_TRANSCRIPTS = os.path.join(YT_AUDIO, \"transcripts\")  # Sub-directory for transcripts of audio files\n",
        "YT_TRANSCRIPTS_TEXT = os.path.join(YT_TRANSCRIPTS, \"full_text\")  # Sub-directory for text of audio files\n",
        "YT_TRANSCRIPTS_WHISPER = os.path.join(YT_TRANSCRIPTS, \"whisper_chunks\")  # Sub-directory for Whisper chunks of audio files\n",
        "YT_TRANSCRIPTS_WHISPER_DISTIL = os.path.join(YT_TRANSCRIPTS, \"distil_whisper_chunks\")  # Sub-directory for Whisper chunks of audio files\n",
        "YT_TRANSCRIPTS_DATASTORE = os.path.join(YT_TRANSCRIPTS, \"datastore\")  # Sub-directory for books FAIS datastore file\n",
        "\n",
        "# Check if directory exists and if not, create it\n",
        "if not os.path.exists(KB_FOLDER):\n",
        "    os.makedirs(KB_FOLDER)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(YT_AUDIO):\n",
        "    os.makedirs(YT_AUDIO)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(YT_TRANSCRIPTS):\n",
        "    os.makedirs(YT_TRANSCRIPTS)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(YT_TRANSCRIPTS_TEXT):\n",
        "    os.makedirs(YT_TRANSCRIPTS_TEXT)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(YT_TRANSCRIPTS_WHISPER):\n",
        "    os.makedirs(YT_TRANSCRIPTS_WHISPER)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(YT_TRANSCRIPTS_WHISPER_DISTIL):\n",
        "    os.makedirs(YT_TRANSCRIPTS_WHISPER_DISTIL)"
      ],
      "id": "ze4wgstKYprq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mHZRgDKXv1r"
      },
      "source": [
        "# Part 2 - Transcribe the audio files\n"
      ],
      "id": "1mHZRgDKXv1r"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ec0N6iFDAu3"
      },
      "source": [
        "# Setup Distil Whisper"
      ],
      "id": "0Ec0N6iFDAu3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wDWtECiHhgF"
      },
      "source": [
        "## Transcribe the audio files and save the text to the Google drive"
      ],
      "id": "_wDWtECiHhgF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_4xqEelud40"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade pip\n",
        "!pip install -q --upgrade transformers accelerate\n",
        "!pip install -q flash-attn --no-build-isolation # Remove if you are using a CPU"
      ],
      "id": "8_4xqEelud40"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYeDA-YGud1-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "\n",
        "device = \"cuda:0\" # This only works with an A100 as it is required for flash-attn. Change to CPU, using a CPU\n",
        "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "model_id = \"distil-whisper/distil-large-v2\"\n",
        "\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch_dtype,\n",
        "    low_cpu_mem_usage=True,\n",
        "    use_safetensors=True,\n",
        "    use_flash_attention_2=True # Remove is using a CPU\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)"
      ],
      "id": "yYeDA-YGud1-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFlpCHuOudzr"
      },
      "outputs": [],
      "source": [
        "pipeline = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=model,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    max_new_tokens=128,\n",
        "    chunk_length_s=15,\n",
        "    batch_size=16,\n",
        "    torch_dtype=torch_dtype,\n",
        "    device=device,\n",
        ")"
      ],
      "id": "BFlpCHuOudzr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNemUO3xG66x"
      },
      "outputs": [],
      "source": [
        "unique_video_ids = []\n",
        "\n",
        "with open(f'{YT_AUDIO}/videos.txt', 'r') as file:\n",
        "    for line in file:\n",
        "        # Remove linebreak which is the last character of the string\n",
        "        curr_place = line[:-1]\n",
        "        # Add item to the list\n",
        "        unique_video_ids.append(curr_place)\n",
        "print(unique_video_ids)"
      ],
      "id": "pNemUO3xG66x"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OKEC3ecWVYT"
      },
      "source": [
        "Cycle through each file and create the transcript. Then save to the Google Drive"
      ],
      "id": "-OKEC3ecWVYT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htBkpQwOHhgQ"
      },
      "outputs": [],
      "source": [
        "import re, json, os, time, math\n",
        "\n",
        "def replace_wordly_with_wardley(transcription):\n",
        "    # Case-insensitive replacement of \"worldy\" and \"worldly\" with \"Wardley\"\n",
        "    for word in [\"wordly\", \"worldly\"]:\n",
        "        pattern = re.compile(word, re.IGNORECASE)\n",
        "        text = transcription['text']\n",
        "        text = pattern.sub(\"Wardley\", text)\n",
        "        transcription['text'] = text\n",
        "        for chunk in transcription['chunks']:\n",
        "            chunk_text = chunk['text']\n",
        "            chunk_text = pattern.sub(\"Wardley\", chunk_text)\n",
        "            chunk['text'] = chunk_text\n",
        "    return transcription\n",
        "\n",
        "def transcribe_file(filename):\n",
        "    print (f\"Transcribing New file: {filename}\")\n",
        "    transcription = pipeline(filename, return_timestamps=True)\n",
        "    transcription = replace_wordly_with_wardley(transcription)\n",
        "    return transcription\n",
        "\n",
        "transcriptions = []\n",
        "total_videos = len(unique_video_ids)\n",
        "\n",
        "for counter, video in enumerate(unique_video_ids, start=1):\n",
        "    transcript_filename = f'{YT_TRANSCRIPTS_WHISPER_DISTIL}/' + video + '_large.txt'\n",
        "    audio_filename = f'{YT_AUDIO}/clips/{video}.webm'\n",
        "    print(f\"{counter} of {total_videos}\")\n",
        "\n",
        "    if not os.path.isfile(transcript_filename):\n",
        "        if os.path.isfile(audio_filename):\n",
        "            start = time.time()\n",
        "            transcription = transcribe_file(audio_filename)\n",
        "            runtime = time.time() - start\n",
        "            rounded_runtime = math.ceil(runtime)  # Round up to the nearest second\n",
        "            print(\"Runtime: \", rounded_runtime, \" seconds\")\n",
        "            print(transcription['text'][:100])\n",
        "            with open(transcript_filename, 'w') as f:\n",
        "                f.write(json.dumps(transcription))\n",
        "        else:\n",
        "            print (f\"File does not exist: {audio_filename}\")\n",
        "    else:\n",
        "        print(f\"Existing File: {transcript_filename}\")\n",
        "        with open(transcript_filename, 'r') as f:\n",
        "            transcription = json.load(f)\n",
        "        print(transcription['text'][:100])\n"
      ],
      "id": "htBkpQwOHhgQ"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "b1677b440931f40d89ef8be7bf03acb108ce003de0ac9b18e8d43753ea2e7103"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}