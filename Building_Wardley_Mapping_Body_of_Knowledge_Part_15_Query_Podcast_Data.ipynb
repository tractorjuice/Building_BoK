{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tractorjuice/Building_BoK/blob/main/Building_Wardley_Mapping_Body_of_Knowledge_Part_15_Query_Podcast_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07c1e3b9"
      },
      "source": [
        "# Wardley Mapping Body of Knowledge Using Langchain & OpenAI\n",
        "## Part 15, query the podcast vector database using ChatGPT\n",
        "\n",
        "This example shows how to create and query an internal knowledge base using ChatGPT.\n",
        "\n",
        "This does not require a GPU runtime."
      ],
      "id": "07c1e3b9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UqlAAxTXnGF"
      },
      "source": [
        "## Set Up\n"
      ],
      "id": "0UqlAAxTXnGF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive"
      ],
      "metadata": {
        "id": "JSzQ8Ud4WeiH"
      },
      "id": "JSzQ8Ud4WeiH"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "8Uynu3LfWYst"
      },
      "id": "8Uynu3LfWYst",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "KB_FOLDER = \"/content/gdrive/MyDrive/AI/WardleyKB\"  # Google drive folder to save the knowledgebase\n",
        "MAPS = os.path.join(KB_FOLDER, \"maps/research2022\")  # Sub-directory for research 2022 files\n",
        "MAPS_DATASTORE = os.path.join(KB_FOLDER, \"maps/datastore\")  # Sub-directory for maps FAIS datastore files\n",
        "YT = os.path.join(KB_FOLDER, \"youtube\")  # Sub-directory for YouTube FAIS datastore files\n",
        "YT_DATASTORE = os.path.join(YT, \"datastore\")  # Sub-directory for YouTube FAIS datastore files\n",
        "YT_AUDIO = os.path.join(YT, \"audio\")  # Sub-directory for audio files\n",
        "YT_TRANSCRIPTS = os.path.join(YT_AUDIO, \"transcripts\")  # Sub-directory for transcripts of audio files\n",
        "YT_TRANSCRIPTS_TEXT = os.path.join(YT_TRANSCRIPTS, \"full_text\")  # Sub-directory for text of audio files\n",
        "YT_TRANSCRIPTS_WHISPER = os.path.join(YT_TRANSCRIPTS, \"whisper_chunks\")  # Sub-directory for Whisper chunks of audio files\n",
        "YT_TRANSCRIPTS_DATASTORE = os.path.join(YT_TRANSCRIPTS, \"datastore\")  # Sub-directory for books FAIS datastore file\n",
        "PODCAST = os.path.join(KB_FOLDER, \"podcast\")  # Sub-directory for YouTube FAIS datastore files\n",
        "PODCAST_DATASTORE = os.path.join(PODCAST, \"datastore\")  # Sub-directory for YouTube FAIS datastore files\n",
        "PODCAST_AUDIO = os.path.join(PODCAST, \"audio\")  # Sub-directory for YouTube FAIS datastore files\n",
        "PODCAST_TRANSCRIPTS = os.path.join(PODCAST, \"transcripts\")  # Sub-directory for YouTube FAIS datastore files\n",
        "BOOKS = os.path.join(KB_FOLDER, \"books\")  # Sub-directory for books FAIS datastore file\n",
        "BOOKS_DATASTORE = os.path.join(BOOKS, \"datastore\")  # Sub-directory for books FAIS datastore file\n",
        "BOOK = os.path.join(BOOKS, \"book\")  # Sub-directory for files of the pages from Wardley book\n",
        "\n",
        "# Check if directory exists and if not, create it\n",
        "if not os.path.exists(KB_FOLDER):\n",
        "    os.makedirs(KB_FOLDER)\n",
        "\n",
        "# Check if directory exists and if not, create it\n",
        "if not os.path.exists(MAPS):\n",
        "    os.makedirs(MAPS)\n",
        "\n",
        "# Check if directory exists and if not, create it\n",
        "if not os.path.exists(MAPS_DATASTORE):\n",
        "    os.makedirs(MAPS_DATASTORE)\n",
        "\n",
        "# Check if directory exists and if not, create it\n",
        "if not os.path.exists(YT_DATASTORE):\n",
        "    os.makedirs(YT_DATASTORE)\n",
        "\n",
        "# Check if directory exists and if not, create it\n",
        "if not os.path.exists(BOOKS_DATASTORE):\n",
        "    os.makedirs(BOOKS_DATASTORE)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(YT_AUDIO):\n",
        "    os.makedirs(YT_AUDIO)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(YT_TRANSCRIPTS):\n",
        "    os.makedirs(YT_TRANSCRIPTS)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(YT_TRANSCRIPTS_TEXT):\n",
        "    os.makedirs(YT_TRANSCRIPTS_TEXT)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(YT_TRANSCRIPTS_WHISPER):\n",
        "    os.makedirs(YT_TRANSCRIPTS_WHISPER)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(BOOKS):\n",
        "    os.makedirs(BOOKS)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(BOOK):\n",
        "    os.makedirs(BOOK)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(PODCAST):\n",
        "    os.makedirs(PODCAST)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(PODCAST_DATASTORE):\n",
        "    os.makedirs(PODCAST_DATASTORE)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(PODCAST_AUDIO):\n",
        "    os.makedirs(PODCAST_AUDIO)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(PODCAST_TRANSCRIPTS):\n",
        "    os.makedirs(PODCAST_TRANSCRIPTS)"
      ],
      "metadata": {
        "id": "vWeQuyzjU0m_"
      },
      "id": "vWeQuyzjU0m_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03__ie72B8J_"
      },
      "source": [
        "Use Pinecone or FAISS for the Vector Database"
      ],
      "id": "03__ie72B8J_"
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = 'FAISS' # Set to 'Pinecone' or 'FAISS' for the vector datbase"
      ],
      "metadata": {
        "id": "cckWJ2E2TAjK"
      },
      "id": "cckWJ2E2TAjK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6TkUqCJB_2X"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain\n",
        "!pip install -q openai\n",
        "!pip install -q tiktoken"
      ],
      "id": "W6TkUqCJB_2X"
    },
    {
      "cell_type": "code",
      "source": [
        "if vectorstore == 'Pinecone':\n",
        "    !pip install -q pinecone-client\n",
        "    from langchain.vectorstores import Pinecone\n",
        "    from tqdm.autonotebook import tqdm\n",
        "    import pinecone\n",
        "\n",
        "    # initialize pinecone\n",
        "    pinecone.init(\n",
        "        api_key=\"\",  # find at app.pinecone.io\n",
        "        environment=\"us-west4-gcp-free\"  # next to api key in console\n",
        "        )\n",
        "\n",
        "    index_name = \"knowledge\" # Put your Pincecone index name here\n",
        "    name_space = \"wardleykb\" # Put your Pincecone namespace here\n",
        "\n",
        "else:\n",
        "    !pip install -q faiss-cpu\n",
        "    from langchain.vectorstores import FAISS\n"
      ],
      "metadata": {
        "id": "YoCtnnwMS9V9"
      },
      "id": "YoCtnnwMS9V9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUbD-eXCXNy-"
      },
      "source": [
        "Set up OPEN_API_KEY and necessary variables"
      ],
      "id": "TUbD-eXCXNy-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY7CJZoh5cma"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\" # add your OpenAI API key here\n",
        "\n",
        "#MODEL = \"gpt-3\"\n",
        "#MODEL = \"gpt-3.5-turbo\"\n",
        "#MODEL = \"gpt-3.5-turbo-0613\"\n",
        "#MODEL = \"gpt-3.5-turbo-16k\"\n",
        "MODEL = \"gpt-3.5-turbo-16k-0613\"\n",
        "#MODEL = \"gpt-4\"\n",
        "#MODEL = \"gpt-4-0613\"\n",
        "#MODEL = \"gpt-4-32k-0613\""
      ],
      "id": "tY7CJZoh5cma"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35f99145"
      },
      "source": [
        "# Query using the vector store with ChatGPT integration"
      ],
      "id": "35f99145"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup access to the Pinecone or FAISS vector database"
      ],
      "metadata": {
        "id": "S5Vf831zQLJa"
      },
      "id": "S5Vf831zQLJa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibz6Tz_7iPeQ"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "id": "ibz6Tz_7iPeQ"
    },
    {
      "cell_type": "code",
      "source": [
        "if vectorstore == 'Pinecone':\n",
        "    vector_store = Pinecone.from_existing_index(index_name, embeddings, namespace=name_space)\n",
        "\n",
        "else:\n",
        "    # Open FAISS datastore\n",
        "    from langchain.vectorstores import FAISS\n",
        "    if os.path.exists(f\"{PODCAST_DATASTORE}\"):\n",
        "        vector_store = FAISS.load_local(\n",
        "            f\"{PODCAST_DATASTORE}\",\n",
        "            OpenAIEmbeddings()\n",
        "            )\n",
        "    else:\n",
        "        print(f\"Missing files. Upload index.faiss and index.pkl files to data_store directory first\")"
      ],
      "metadata": {
        "id": "QQDKy5IRT98I"
      },
      "id": "QQDKy5IRT98I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup the prompt"
      ],
      "metadata": {
        "id": "WDcuSm-wQPC-"
      },
      "id": "WDcuSm-wQPC-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32a49412"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "system_template=\"\"\"\n",
        "    You are an Data Mesh researcher based in the UK with well over twenty years research in Data arcitecture, DataOps and Data Mesh.\n",
        "    You use examples from Data Mesh in your answers.\n",
        "    Your language should be for a 12 year old to understand.\n",
        "    If you do not know the answer to a question, do not make information up - instead, ask a follow-up question in order to gain more context.\n",
        "    Use a mix of technical and colloquial uk english language to create an accessible and engaging tone.\n",
        "    Use the following pieces of context to answer the users question.\n",
        "    Take note of the sources and include them in the answer in the format: \"SOURCES: source1 source2\", use \"SOURCES\" in capital letters regardless of the number of sources.\n",
        "----------------\n",
        "{summaries}\n",
        "\"\"\"\n",
        "messages = [\n",
        "    SystemMessagePromptTemplate.from_template(system_template),\n",
        "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "]\n",
        "prompt = ChatPromptTemplate.from_messages(messages)"
      ],
      "id": "32a49412"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialise the LLM API"
      ],
      "metadata": {
        "id": "jlIfoZccQRmm"
      },
      "id": "jlIfoZccQRmm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3018f865"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "\n",
        "chain_type_kwargs = {\"prompt\": prompt}\n",
        "llm = ChatOpenAI(model_name=MODEL, temperature=0)  # Modify model_name if you have access to GPT-4\n",
        "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vector_store.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 10}), # Use MMR search and return 5 (max 20) sources\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs=chain_type_kwargs\n",
        ")"
      ],
      "id": "3018f865"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNjGnZME_DNU"
      },
      "source": [
        "#### Use the chain to query"
      ],
      "id": "eNjGnZME_DNU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "032a47f8"
      },
      "outputs": [],
      "source": [
        "query = \"what are the key concepts of a datamesh?\"\n",
        "result = chain(query)"
      ],
      "id": "032a47f8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the sources so we can find the Google Podcasts"
      ],
      "metadata": {
        "id": "6_aZT0JXPr_9"
      },
      "id": "6_aZT0JXPr_9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcrUA39A86G6"
      },
      "outputs": [],
      "source": [
        "print(result['question'])\n",
        "print(result['answer'])\n",
        "\n",
        "source_documents = result['source_documents']\n",
        "for index, document in enumerate(source_documents):\n",
        "    print(f\"\\nSource {index + 1}:\")\n",
        "    podcast_filename = document.metadata['source_url']\n",
        "    podcast_name = os.path.splitext(podcast_filename)[0]\n",
        "    print(f\"Source podcast: https://podcasts.google.com/feed/aHR0cHM6Ly9mZWVkcy5jYXB0aXZhdGUuZm0vZGF0YS1tZXNoLXJhZGlv/episode/{podcast_name}?t={int(document.metadata['source'])}\")\n",
        "    print(f\"Content: {document.page_content}\")"
      ],
      "id": "AcrUA39A86G6"
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what does a typical datamesh instructure look like?\"\n",
        "result = chain(query)"
      ],
      "metadata": {
        "id": "rAzx7aqHXN4W"
      },
      "id": "rAzx7aqHXN4W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['question'])\n",
        "print(result['answer'])\n",
        "\n",
        "source_documents = result['source_documents']\n",
        "for index, document in enumerate(source_documents):\n",
        "    print(f\"\\nSource {index + 1}:\")\n",
        "    podcast_filename = document.metadata['source_url']\n",
        "    podcast_name = os.path.splitext(podcast_filename)[0]\n",
        "    print(f\"Source podcast: https://podcasts.google.com/feed/aHR0cHM6Ly9mZWVkcy5jYXB0aXZhdGUuZm0vZGF0YS1tZXNoLXJhZGlv/episode/{podcast_name}?t={int(document.metadata['source'])}\")\n",
        "    print(f\"Content: {document.page_content}\")"
      ],
      "metadata": {
        "id": "yW79u1avXThz"
      },
      "id": "yW79u1avXThz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is domain-oriented decentralized data ownership?\"\n",
        "result = chain(query)"
      ],
      "metadata": {
        "id": "Q7Sy6pMjYedU"
      },
      "id": "Q7Sy6pMjYedU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['question'])\n",
        "print(result['answer'])\n",
        "\n",
        "source_documents = result['source_documents']\n",
        "for index, document in enumerate(source_documents):\n",
        "    print(f\"\\nSource {index + 1}:\")\n",
        "    podcast_filename = document.metadata['source_url']\n",
        "    podcast_name = os.path.splitext(podcast_filename)[0]\n",
        "    print(f\"Source podcast: https://podcasts.google.com/feed/aHR0cHM6Ly9mZWVkcy5jYXB0aXZhdGUuZm0vZGF0YS1tZXNoLXJhZGlv/episode/{podcast_name}?t={int(document.metadata['source'])}\")\n",
        "    print(f\"Content: {document.page_content}\")"
      ],
      "metadata": {
        "id": "UQR5xUIXYhvi"
      },
      "id": "UQR5xUIXYhvi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what tools enable control and autonomy over data?\"\n",
        "result = chain(query)"
      ],
      "metadata": {
        "id": "ujSaUU1GZAEd"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ujSaUU1GZAEd"
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['question'])\n",
        "print(result['answer'])\n",
        "\n",
        "source_documents = result['source_documents']\n",
        "for index, document in enumerate(source_documents):\n",
        "    print(f\"\\nSource {index + 1}:\")\n",
        "    podcast_filename = document.metadata['source_url']\n",
        "    podcast_name = os.path.splitext(podcast_filename)[0]\n",
        "    print(f\"Source podcast: https://podcasts.google.com/feed/aHR0cHM6Ly9mZWVkcy5jYXB0aXZhdGUuZm0vZGF0YS1tZXNoLXJhZGlv/episode/{podcast_name}?t={int(document.metadata['source'])}\")\n",
        "    print(f\"Content: {document.page_content}\")"
      ],
      "metadata": {
        "id": "_Lh4AGTgZAEg"
      },
      "execution_count": null,
      "outputs": [],
      "id": "_Lh4AGTgZAEg"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuClass": "premium",
      "collapsed_sections": [
        "0UqlAAxTXnGF"
      ],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "b1677b440931f40d89ef8be7bf03acb108ce003de0ac9b18e8d43753ea2e7103"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}