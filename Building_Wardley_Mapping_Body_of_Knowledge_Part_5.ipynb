{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tractorjuice/Building_BoK/blob/main/Building_Wardley_Mapping_Body_of_Knowledge_Part_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07c1e3b9"
      },
      "source": [
        "# Building a Body of Knowledge using Pinecone, Langchain and OpenAI\n",
        "## Part 5, query the PDF book using ChatGPT\n",
        "\n",
        "This example shows how to create and query an internal knowledge base using ChatGPT.\n",
        "\n",
        "This does not require a GPU runtime."
      ],
      "id": "07c1e3b9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UqlAAxTXnGF"
      },
      "source": [
        "## Set Up\n"
      ],
      "id": "0UqlAAxTXnGF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4Lw2Ast5ePE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "A4Lw2Ast5ePE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWvhZqL5oFFq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "DOCS_FOLDER = \"/content/gdrive/Mydrive/WardleyKB\"  # Google drive folder to save the audio clips from YouTube videos\n",
        "BOOK_FOLDER = os.path.join(DOCS_FOLDER, \"book\")  # Sub-directory for audio files\n",
        "PAGES_FOLDER = os.path.join(BOOK_FOLDER, \"pages\")  # Sub-directory for audio files\n",
        "\n",
        "# Check if directory exists and if not, create it\n",
        "if not os.path.exists(DOCS_FOLDER):\n",
        "    os.makedirs(DOCS_FOLDER)\n",
        "\n",
        "# Check if sub-directory for audio exists and if not, create it\n",
        "if not os.path.exists(BOOK_FOLDER):\n",
        "    os.makedirs(BOOK_FOLDER)\n",
        "\n",
        "# Check if sub-directory for audio exists and if not, create it\n",
        "if not os.path.exists(PAGES_FOLDER):\n",
        "    os.makedirs(PAGES_FOLDER)\n"
      ],
      "id": "AWvhZqL5oFFq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mHZRgDKXv1r"
      },
      "source": [
        "## Build the datastore"
      ],
      "id": "1mHZRgDKXv1r"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfkgVeTzNv1x"
      },
      "source": [
        "### Load documents and split them into chunks for conversion to embeddings"
      ],
      "id": "tfkgVeTzNv1x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvJ9T2IEqVMP"
      },
      "outputs": [],
      "source": [
        "!pip install -q pypdf\n",
        "!pip install -q langchain\n",
        "!pip install -q openai"
      ],
      "id": "OvJ9T2IEqVMP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scan and find all documents"
      ],
      "metadata": {
        "id": "xAeOJMrRw80E"
      },
      "id": "xAeOJMrRw80E"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhX0M9Dp60jF"
      },
      "outputs": [],
      "source": [
        "documents = []\n",
        "for root, dirs, files in os.walk(PAGES_FOLDER):\n",
        "    for name in files:\n",
        "        documents.append(os.path.join(root, name))\n",
        "\n",
        "print(documents)"
      ],
      "id": "HhX0M9Dp60jF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpTi97ZFON4b"
      },
      "source": [
        "### Setup Pinecone Vector Store"
      ],
      "id": "QpTi97ZFON4b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71fF2lhe53Qa"
      },
      "outputs": [],
      "source": [
        "!pip install -q pinecone-client\n",
        "!pip install tiktoken\n",
        "from langchain.vectorstores import Pinecone\n",
        "from tqdm.auto import tqdm\n",
        "import pinecone\n",
        "\n",
        "# initialize pinecone\n",
        "pinecone.init(\n",
        "    api_key=\"\",  # find at app.pinecone.io\n",
        "    environment=\"\"  # next to api key in console\n",
        "    )\n",
        "\n",
        "index_name = \"\"\n",
        "name_space = \"\""
      ],
      "id": "71fF2lhe53Qa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUbD-eXCXNy-"
      },
      "source": [
        "### Set up OPEN_API_KEY and necessary variables"
      ],
      "id": "TUbD-eXCXNy-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY7CJZoh5cma"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ],
      "id": "tY7CJZoh5cma"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEsMw4Al3xSr"
      },
      "source": [
        "### Upsert data into vector database"
      ],
      "id": "XEsMw4Al3xSr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5Fcd6dgK6JZ"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader# Core Requirements\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "for files in documents:\n",
        "    pages = []\n",
        "    loader = PyPDFLoader(files)\n",
        "    pages.extend(loader.load_and_split())\n",
        "    print (pages)\n",
        "\n",
        "    vector_store = Pinecone.from_documents(pages, embeddings, namespace=name_space, index_name=index_name)"
      ],
      "id": "B5Fcd6dgK6JZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35f99145"
      },
      "source": [
        "## Query using the vector store with ChatGPT integration\n",
        "### Set up the chat model and specific prompt"
      ],
      "id": "35f99145"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOlYA0ZPuTah"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vector_store = Pinecone.from_existing_index(index_name, embeddings, namespace=name_space)"
      ],
      "id": "xOlYA0ZPuTah"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32a49412"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "system_template=\"\"\"Use the following pieces of context to answer the users question.\n",
        "Take note of the sources and include them in the answer in the format: \"SOURCES: source1 source2\", use \"SOURCES\" in capital letters regardless of the number of sources.\n",
        "If you don't know the answer, just say that \"I don't know\", don't try to make up an answer.\n",
        "----------------\n",
        "{summaries}\"\"\"\n",
        "messages = [\n",
        "    SystemMessagePromptTemplate.from_template(system_template),\n",
        "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "]\n",
        "prompt = ChatPromptTemplate.from_messages(messages)"
      ],
      "id": "32a49412"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3018f865"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "\n",
        "chain_type_kwargs = {\"prompt\": prompt}\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, max_tokens=256)  # Modify model_name if you have access to GPT-4\n",
        "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vector_store.as_retriever(),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs=chain_type_kwargs\n",
        ")"
      ],
      "id": "3018f865"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNjGnZME_DNU"
      },
      "source": [
        "#### Use the chain to query"
      ],
      "id": "eNjGnZME_DNU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "032a47f8"
      },
      "outputs": [],
      "source": [
        "query = \"what is inertia?\"\n",
        "result = chain(query)"
      ],
      "id": "032a47f8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFyy2VhI7CKw"
      },
      "outputs": [],
      "source": [
        "print(result['question'])\n",
        "print(result['answer'])\n",
        "print(result['sources'])\n",
        "print(result)"
      ],
      "id": "UFyy2VhI7CKw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAjOZ0fE7DUl"
      },
      "outputs": [],
      "source": [
        "source_documents = result['source_documents']\n",
        "for index, document in enumerate(source_documents):\n",
        "    print(f\"Source {index + 1}:\\n\")\n",
        "    print(f\"Page Content: {document.page_content}\\n\")\n",
        "    print(f\"Source: {document.metadata['source']}\\n\")"
      ],
      "id": "SAjOZ0fE7DUl"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "b1677b440931f40d89ef8be7bf03acb108ce003de0ac9b18e8d43753ea2e7103"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}